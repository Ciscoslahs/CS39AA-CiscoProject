{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"bb3398f4b21c7b026dd5874af3f954bf25f1e8ff81e25d82a94abcbbaacf760b"}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1282,"sourceType":"datasetVersion","datasetId":673},{"sourceId":7114815,"sourceType":"datasetVersion","datasetId":4103004}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project Part 3\n\n[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/ciscoyslas/deeplearningmodelyslas/edit)\n\n\n_This notebook will build a deep learning model to predict ABV (Alcohol by Volume) from a dataset of craft beers._","metadata":{}},{"cell_type":"markdown","source":"## 1. Introduction/Background\n\n","metadata":{}},{"cell_type":"markdown","source":"## 2. Exploratory Data Analysis\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Input, Embedding, Flatten, Concatenate\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:29:15.202425Z","iopub.execute_input":"2023-12-03T20:29:15.203036Z","iopub.status.idle":"2023-12-03T20:29:25.792348Z","shell.execute_reply.started":"2023-12-03T20:29:15.203000Z","shell.execute_reply":"2023-12-03T20:29:25.790970Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"<frozen importlib._bootstrap>:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n","output_type":"stream"}]},{"cell_type":"code","source":"beers_df = pd.read_csv('/kaggle/input/craft-cans/beers.csv')\ntest_df = pd.read_csv('/kaggle/input/craft-cans/beers.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:21:29.966568Z","iopub.execute_input":"2023-12-03T20:21:29.967177Z","iopub.status.idle":"2023-12-03T20:21:29.998545Z","shell.execute_reply.started":"2023-12-03T20:21:29.967143Z","shell.execute_reply":"2023-12-03T20:21:29.997785Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Loading pre-trained Word2Vec embeddings\nword2vec_path = '/kaggle/input/word-embeddings/GoogleNews-vectors-negative300.bin'\nword2vec_model = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n\n\n# Tokenize and pad sequences for the 'style' column\nmax_sequence_length_style = 50\ntext_data_style = pad_sequences(beers_df['style'].apply(lambda x: [word2vec_model.key_to_index[word] for word in str(x).split() if word in word2vec_model.key_to_index]).tolist(), maxlen=max_sequence_length_style)\n\n# Tokenize and pad sequences for the 'name' column\nmax_sequence_length_name = 20 \ntext_data_name = pad_sequences(beers_df['name'].apply(lambda x: [word2vec_model.key_to_index[word] for word in str(x).split() if word in word2vec_model.key_to_index]).tolist(), maxlen=max_sequence_length_name)\n\n# Normalize numerical features\nnumerical_data = MinMaxScaler().fit_transform(beers_df[['ibu', 'ounces']].values)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:21:32.398595Z","iopub.execute_input":"2023-12-03T20:21:32.399632Z","iopub.status.idle":"2023-12-03T20:22:38.128259Z","shell.execute_reply.started":"2023-12-03T20:21:32.399594Z","shell.execute_reply":"2023-12-03T20:22:38.127278Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Concatenate text and numerical features\nX_text = np.concatenate([text_data_style, text_data_name], axis=1)\nX_num = numerical_data\ny = beers_df['abv'].values\n\n#Define input layers\ninput_text = Input(shape=(max_sequence_length_style + max_sequence_length_name,))\ninput_num = Input(shape=(2,)) \n\n# Word embedding layer for text data\nembedding_layer = Embedding(input_dim=len(word2vec_model.key_to_index), output_dim=300, input_length=max_sequence_length_style + max_sequence_length_name)(input_text)\nflatten_layer = Flatten()(embedding_layer)\n\n# Concatenate the flattened text data and numerical data\nconcatenated_layer = Concatenate()([flatten_layer, input_num])\n\n# Dense layers for the combined data\ndense1 = Dense(128, activation='relu')(concatenated_layer)\noutput_layer = Dense(1)(dense1)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:22:51.886516Z","iopub.execute_input":"2023-12-03T20:22:51.887257Z","iopub.status.idle":"2023-12-03T20:22:55.000048Z","shell.execute_reply.started":"2023-12-03T20:22:51.887217Z","shell.execute_reply":"2023-12-03T20:22:54.999262Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Define the model\nmodel = Model(inputs=[input_text, input_num], outputs=output_layer)\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n\n# Split the data into training and validation sets\nX_train_text, X_val_text, X_train_num, X_val_num, y_train, y_val = train_test_split(X_text, X_num, y, test_size=0.2, random_state=42)\n\n# Train the model\nmodel.fit([X_train_text, X_train_num], y_train, epochs=10, batch_size = 16, validation_data=([X_val_text, X_val_num], y_val))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:29:09.880977Z","iopub.execute_input":"2023-12-03T20:29:09.881620Z","iopub.status.idle":"2023-12-03T20:29:10.217743Z","shell.execute_reply.started":"2023-12-03T20:29:09.881582Z","shell.execute_reply":"2023-12-03T20:29:10.216530Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m(inputs\u001b[38;5;241m=\u001b[39m[input_text, input_num], outputs\u001b[38;5;241m=\u001b[39moutput_layer)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"],"ename":"NameError","evalue":"name 'Model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Evaluate the model on a test set\nX_test_text_style = pad_sequences(test_df['style'].apply(lambda x: [word2vec_model.key_to_index[word] for word in str(x).split() if word in word2vec_model.key_to_index]).tolist(), maxlen=max_sequence_length_style)\nX_test_text_name = pad_sequences(test_df['name'].apply(lambda x: [word2vec_model.key_to_index[word] for word in str(x).split() if word in word2vec_model.key_to_index]).tolist(), maxlen=max_sequence_length_name)\nX_test_num = MinMaxScaler().fit_transform(test_df[['ibu', 'ounces']].values)\nmodel.evaluate([np.concatenate([X_test_text_style, X_test_text_name], axis=1), X_test_num], test_df['abv'].values)\n","metadata":{},"execution_count":null,"outputs":[]}]}